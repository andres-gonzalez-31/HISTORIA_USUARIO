{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fe3459",
   "metadata": {},
   "source": [
    "## Celda 1: Definici√≥n de la Clase de Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87f2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "## H2.ipynb - Celda 1: Definici√≥n de la Clase de Limpieza (COMPLETA)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "# Importaciones para el reporte de calidad\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- INICIO CLASE LimpiezaAutomatizada (C√≥digo COMPLETO) ---\n",
    "\n",
    "class LimpiezaAutomatizada:\n",
    "    \"\"\"\n",
    "    Sistema automatizado y reutilizable para limpieza de datos\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, archivo_csv: str, config_limpieza: Dict = None):\n",
    "        self.archivo_csv = archivo_csv\n",
    "        self.df = None\n",
    "        self.estadisticas_limpieza = {}\n",
    "        self.config_limpieza = config_limpieza or self._configuracion_predeterminada()\n",
    "        \n",
    "    def _configuracion_predeterminada(self) -> Dict:\n",
    "        \"\"\"Configuraci√≥n predeterminada para limpieza\"\"\"\n",
    "        return {\n",
    "            'mapeo_columnas': {\n",
    "                'fecha': ['fecha', 'date', 'fecha_venta', 'timestamp'],\n",
    "                'producto': ['producto', 'product', 'item', 'descripcion'],\n",
    "                'tipo_producto': ['tipo_producto', 'categoria', 'category'],\n",
    "                'cantidad': ['cantidad', 'qty', 'quantity', 'unidades'],\n",
    "                'precio_unitario': ['precio_unitario', 'precio', 'price', 'unit_price'],\n",
    "                'total_ventas': ['total_ventas', 'venta_total', 'total', 'amount', 'importe'],\n",
    "                'tipo_venta': ['tipo_venta', 'canal_venta', 'channel'],\n",
    "                'tipo_cliente': ['tipo_cliente', 'customer_type', 'segmento_cliente'],\n",
    "                'descuento': ['descuento', 'discount'],\n",
    "                'costo_envio': ['costo_envio', 'shipping_cost'],\n",
    "                'ciudad': ['ciudad', 'city', 'localidad'],\n",
    "                'pais': ['pais', 'country'],\n",
    "                'region': ['region', 'state', 'estado']\n",
    "            },\n",
    "            'reglas_limpieza': {\n",
    "                'texto': { 'case': 'title' }, \n",
    "                'numero': {\n",
    "                    'min_value': 0, \n",
    "                    'max_value': 1000000, \n",
    "                    'decimales': 2\n",
    "                },\n",
    "                'fecha': {\n",
    "                    'formatos': ['%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y', '%Y-%m-%d %H:%M:%S', \n",
    "                                 '%d-%m-%Y', '%m-%d-%Y', '%Y/%m/%d'],\n",
    "                    'rango_min': '2020-01-01',\n",
    "                    'rango_max': '2025-12-31'\n",
    "                }\n",
    "            },\n",
    "            'columnas_orden_preferido': [\n",
    "                'fecha', 'producto', 'tipo_producto', 'cantidad', 'precio_unitario',\n",
    "                'ciudad', 'pais', 'tipo_venta', 'tipo_cliente', 'descuento', 'costo_envio', 'total_ventas'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    # --- M√âTODOS DE UTILIDAD Y VALIDACI√ìN (No cambiaron) ---\n",
    "    def _normalizar_texto(self, texto: Any) -> str:\n",
    "        if pd.isna(texto): return \"\"\n",
    "        texto = str(texto).lower().strip()\n",
    "        texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        texto = re.sub(r'[^a-z0-9\\s]', '', texto)\n",
    "        return texto\n",
    "\n",
    "    def _es_numerico(self, valor: str) -> bool:\n",
    "        try:\n",
    "            valor_limpio = re.sub(r'[^0-9.\\-]', '', str(valor))\n",
    "            if not valor_limpio or valor_limpio == '-': return False\n",
    "            float(valor_limpio)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def _es_fecha_valida(self, valor: str) -> bool:\n",
    "        formatos = self.config_limpieza['reglas_limpieza']['fecha']['formatos']\n",
    "        for formato in formatos:\n",
    "            try:\n",
    "                datetime.strptime(str(valor), formato)\n",
    "                return True\n",
    "            except ValueError:\n",
    "                continue\n",
    "        try:\n",
    "            pd.to_datetime(valor, errors='raise')\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "            \n",
    "    def _determinar_tipo_columna(self, serie: pd.Series) -> str:\n",
    "        if serie.empty or serie.dropna().empty: return 'desconocido'\n",
    "        serie_str = serie.dropna().astype(str)\n",
    "        if len(serie_str) == 0: return 'desconocido'\n",
    "        \n",
    "        if serie_str.apply(self._es_fecha_valida).sum() / len(serie_str) > 0.5:\n",
    "            return 'fecha'\n",
    "        \n",
    "        if serie_str.apply(self._es_numerico).sum() / len(serie_str) > 0.8:\n",
    "            return 'numero'\n",
    "        \n",
    "        return 'texto'\n",
    "\n",
    "    # --- M√âTODOS DE LIMPIEZA ESPEC√çFICA (No cambiaron) ---\n",
    "    # (Se omite el c√≥digo de _limpiar_texto, _limpiar_numero, _limpiar_fecha, _limpiar_booleano, _limpiar_numero_robusto, _aplicar_limpieza_por_tipo para brevedad, pero debe estar completo en la celda)\n",
    "    def _limpiar_texto(self, serie: pd.Series) -> pd.Series:\n",
    "        def limpiar_valor(valor):\n",
    "            if pd.isna(valor): return np.nan\n",
    "            valor_str = str(valor).strip()\n",
    "            valor_limpio = re.sub(r'[^a-zA-Z0-9√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë√º√ú\\s\\-_\\.]', ' ', valor_str)\n",
    "            valor_limpio = re.sub(r'\\s+', ' ', valor_limpio).strip()\n",
    "            if not valor_limpio: return np.nan\n",
    "            \n",
    "            config_case = self.config_limpieza['reglas_limpieza']['texto']['case']\n",
    "            if config_case == 'lower': return valor_limpio.lower()\n",
    "            elif config_case == 'upper': return valor_limpio.upper()\n",
    "            elif config_case == 'title': return valor_limpio.title()\n",
    "            else: return valor_limpio\n",
    "        \n",
    "        return serie.apply(limpiar_valor)\n",
    "        \n",
    "    def _limpiar_numero(self, serie: pd.Series) -> pd.Series:\n",
    "        def limpiar_valor(valor):\n",
    "            if pd.isna(valor): return np.nan\n",
    "            try:\n",
    "                valor_limpio = re.sub(r'[^0-9.\\-]', '', str(valor))\n",
    "                if not valor_limpio or valor_limpio == '-': return np.nan\n",
    "                \n",
    "                numero = float(valor_limpio)\n",
    "                \n",
    "                min_val = self.config_limpieza['reglas_limpieza']['numero']['min_value']\n",
    "                max_val = self.config_limpieza['reglas_limpieza']['numero']['max_value']\n",
    "                decimales = self.config_limpieza['reglas_limpieza']['numero']['decimales']\n",
    "                \n",
    "                if numero < min_val or numero > max_val: return np.nan\n",
    "                \n",
    "                return round(numero, decimales)\n",
    "            except (ValueError, TypeError):\n",
    "                return np.nan\n",
    "        \n",
    "        return serie.apply(limpiar_valor)\n",
    "\n",
    "    def _limpiar_fecha(self, serie: pd.Series) -> pd.Series:\n",
    "        def limpiar_valor(valor):\n",
    "            if pd.isna(valor): return np.nan\n",
    "            try:\n",
    "                formatos = self.config_limpieza['reglas_limpieza']['fecha']['formatos']\n",
    "                fecha = None\n",
    "                for formato in formatos:\n",
    "                    try:\n",
    "                        fecha = datetime.strptime(str(valor), formato)\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                if fecha is None: fecha = pd.to_datetime(valor, errors='coerce')\n",
    "                if pd.isna(fecha): return np.nan\n",
    "                rango_min = pd.to_datetime(self.config_limpieza['reglas_limpieza']['fecha']['rango_min'])\n",
    "                rango_max = pd.to_datetime(self.config_limpieza['reglas_limpieza']['fecha']['rango_max'])\n",
    "                if pd.to_datetime(fecha) < rango_min or pd.to_datetime(fecha) > rango_max:\n",
    "                    return np.nan\n",
    "                return fecha.strftime('%Y-%m-%d')\n",
    "            except Exception as e:\n",
    "                return np.nan\n",
    "        return serie.apply(limpiar_valor)\n",
    "\n",
    "    def _limpiar_booleano(self, serie: pd.Series) -> pd.Series:\n",
    "        mapa_valores = {\n",
    "            'true': True, 'false': False, '1': True, '0': False,\n",
    "            'si': True, 'no': False, 's√≠': True, 'yes': True, \n",
    "            'verdadero': True, 'falso': False, 't': True, 'f': False, 'v': True\n",
    "        }\n",
    "        def limpiar_valor(valor):\n",
    "            if pd.isna(valor): return np.nan\n",
    "            try:\n",
    "                valor_str = str(valor).lower().strip()\n",
    "                valor_str = re.sub(r'\\s+', ' ', valor_str).strip()\n",
    "                return mapa_valores.get(valor_str, np.nan)\n",
    "            except:\n",
    "                return np.nan\n",
    "        return serie.apply(limpiar_valor)\n",
    "\n",
    "    def _limpiar_numero_robusto(self, serie: pd.Series) -> pd.Series:\n",
    "        serie_limpia = pd.to_numeric(serie, errors='coerce')\n",
    "        if serie_limpia.isna().sum() > len(serie) * 0.5:\n",
    "            print(f\"      Muchos valores no num√©ricos en {serie.name}, aplicando limpieza manual...\")\n",
    "            serie_limpia = self._limpiar_numero(serie) \n",
    "        min_val = self.config_limpieza['reglas_limpieza']['numero']['min_value']\n",
    "        decimales = self.config_limpieza['reglas_limpieza']['numero']['decimales']\n",
    "        serie_limpia = serie_limpia.clip(lower=min_val)\n",
    "        if decimales is not None:\n",
    "            serie_limpia = serie_limpia.round(decimales)\n",
    "        return serie_limpia\n",
    "\n",
    "    def _aplicar_limpieza_por_tipo(self):\n",
    "        print(\"üßπ Aplicando limpieza por tipo de dato...\")\n",
    "        columnas_numericas_criticas = ['cantidad', 'precio_unitario', 'descuento', 'costo_envio']\n",
    "        for columna in columnas_numericas_criticas:\n",
    "            if columna in self.df.columns:\n",
    "                self.df[columna] = self._limpiar_numero_robusto(self.df[columna])\n",
    "                if columna in ['cantidad', 'precio_unitario']: self.df[columna].fillna(0, inplace=True) \n",
    "        for columna in self.df.columns:\n",
    "            if columna in columnas_numericas_criticas: continue\n",
    "            if columna not in self.df.columns or self.df[columna].empty: continue\n",
    "            tipo = self._determinar_tipo_columna(self.df[columna])\n",
    "            \n",
    "            try:\n",
    "                if tipo == 'texto': self.df[columna] = self._limpiar_texto(self.df[columna])\n",
    "                elif tipo == 'numero': self.df[columna] = self._limpiar_numero_robusto(self.df[columna])\n",
    "                elif tipo == 'fecha': self.df[columna] = self._limpiar_fecha(self.df[columna])\n",
    "                elif tipo == 'booleano': self.df[columna] = self._limpiar_booleano(self.df[columna])\n",
    "                else: self.df[columna] = self._limpiar_texto(self.df[columna])\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö† Advertencia limpiando {columna}: {e}\")\n",
    "        print(\"   ‚úÖ Limpieza por tipo de dato completada.\")\n",
    "    # --- FIN M√âTODOS DE LIMPIEZA ESPEC√çFICA ---\n",
    "\n",
    "\n",
    "    # --- M√âTODOS DE C√ÅLCULO Y ESTRUCTURA (No cambiaron) ---\n",
    "    def _calcular_total_ventas(self):\n",
    "        if 'total_ventas' not in self.df.columns or self.df['total_ventas'].isnull().all():\n",
    "            if 'cantidad' in self.df.columns and 'precio_unitario' in self.df.columns:\n",
    "                print(\"üí∞ Calculando columna total_ventas...\")\n",
    "                cantidad = self.df['cantidad'].fillna(0)\n",
    "                precio = self.df['precio_unitario'].fillna(0)\n",
    "                self.df['total_ventas'] = cantidad * precio\n",
    "                if 'descuento' in self.df.columns:\n",
    "                    descuento = self.df['descuento'].fillna(0)\n",
    "                    self.df['total_ventas'] = self.df['total_ventas'] * (1 - descuento / 100)\n",
    "                print(f\"   ‚úÖ Total_ventas calculado.\")\n",
    "            else:\n",
    "                print(\"‚ö† No se puede calcular total_ventas - faltan columnas requeridas (cantidad/precio_unitario)\")\n",
    "    \n",
    "    def _reorganizar_datos_mal_estructurados(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(\"üîÑ Reorganizando datos mal estructurados...\")\n",
    "        columnas_actuales = df.columns.tolist()\n",
    "        if len(columnas_actuales) >= 10 and 'ciudad' not in df.columns:\n",
    "            try:\n",
    "                nuevos_datos = []\n",
    "                for _, fila in df.iterrows():\n",
    "                    nueva_fila = {\n",
    "                        'ciudad': str(fila.iloc[0]) if len(fila) > 0 else '', 'fecha': str(fila.iloc[1]) if len(fila) > 1 else '',\n",
    "                        'producto': str(fila.iloc[2]) if len(fila) > 2 else '', 'tipo_producto': str(fila.iloc[3]) if len(fila) > 3 else '',\n",
    "                        'cantidad': str(fila.iloc[4]) if len(fila) > 4 else '', 'precio_unitario': str(fila.iloc[5]) if len(fila) > 5 else '',\n",
    "                        'tipo_venta': str(fila.iloc[6]) if len(fila) > 6 else '', 'tipo_cliente': str(fila.iloc[7]) if len(fila) > 7 else '',\n",
    "                        'descuento': str(fila.iloc[8]) if len(fila) > 8 else '', 'costo_envio': str(fila.iloc[9]) if len(fila) > 9 else '',\n",
    "                        'pais': '' \n",
    "                    }\n",
    "                    nuevos_datos.append(nueva_fila)\n",
    "                df_corregido = pd.DataFrame(nuevos_datos)\n",
    "                print(f\"   ‚úÖ Datos reorganizados: {len(df_corregido)} filas\")\n",
    "                return df_corregido\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö† Error reorganizando datos: {e}\")\n",
    "                return df\n",
    "        else:\n",
    "            print(\"   ‚ÑπÔ∏è  Estructura de columnas parece correcta\")\n",
    "            return df\n",
    "    \n",
    "    def _mapear_columnas_automatico(self, columnas_originales: List[str]) -> Dict:\n",
    "        mapeo = {}; columnas_mapeadas = set(); columnas_no_mapeadas = columnas_originales.copy()\n",
    "        for nombre_estandar, variantes in self.config_limpieza['mapeo_columnas'].items():\n",
    "            for columna_original in columnas_originales:\n",
    "                if columna_original in columnas_mapeadas: continue\n",
    "                col_clean = self._normalizar_texto(columna_original)\n",
    "                for variante in variantes:\n",
    "                    variante_clean = self._normalizar_texto(variante)\n",
    "                    if variante_clean == col_clean or (variante_clean in col_clean or col_clean in variante_clean) and len(col_clean) > 2:\n",
    "                        if nombre_estandar not in mapeo.values():\n",
    "                            mapeo[columna_original] = nombre_estandar\n",
    "                            columnas_mapeadas.add(columna_original)\n",
    "                            if columna_original in columnas_no_mapeadas: columnas_no_mapeadas.remove(columna_original)\n",
    "                            break\n",
    "        nombres_estandar_usados = set(mapeo.values())\n",
    "        temp_no_mapeadas = columnas_no_mapeadas.copy()\n",
    "        for i, columna in enumerate(temp_no_mapeadas):\n",
    "            if columna not in mapeo:\n",
    "                nombre_estandar = f\"columna_{i+1}\"\n",
    "                while nombre_estandar in nombres_estandar_usados:\n",
    "                    i += 1\n",
    "                    nombre_estandar = f\"columna_{i+1}\"\n",
    "                mapeo[columna] = nombre_estandar\n",
    "                nombres_estandar_usados.add(nombre_estandar)\n",
    "        return mapeo\n",
    "\n",
    "    def _detectar_y_corregir_pais(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(\"   üó∫Ô∏è  Detectando pa√≠ses basado en ciudades...\")\n",
    "        mapeo_ciudad_pais = {\n",
    "            'bogota': 'Colombia', 'medellin': 'Colombia', 'cali': 'Colombia',\n",
    "            'new york': 'Estados Unidos', 'madrid': 'Espa√±a', 'ciudad de mexico': 'M√©xico', \n",
    "            'buenos aires': 'Argentina', 'sao paulo': 'Brasil', 'lima': 'Per√∫', 'santiago': 'Chile' \n",
    "        }\n",
    "        def detectar_pais(ciudad):\n",
    "            if pd.isna(ciudad) or str(ciudad).strip() == '': return 'Desconocido'\n",
    "            ciudad_clean = self._normalizar_texto(ciudad)\n",
    "            for ciudad_mapeo, pais in mapeo_ciudad_pais.items():\n",
    "                if ciudad_clean == self._normalizar_texto(ciudad_mapeo): return pais\n",
    "            return 'Desconocido'\n",
    "        if 'ciudad' in df.columns:\n",
    "            df['pais'] = df['ciudad'].apply(detectar_pais)\n",
    "            print(f\"   ‚úÖ Pa√≠ses detectados: {df['pais'].value_counts().to_dict()}\")\n",
    "        return df\n",
    "\n",
    "    def _eliminar_columnas_duplicadas(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(\"üîç Buscando columnas duplicadas...\")\n",
    "        columnas_a_mantener = []; columnas_vistas = set()\n",
    "        for columna in df.columns:\n",
    "            if columna not in columnas_vistas:\n",
    "                columnas_a_mantener.append(columna)\n",
    "                columnas_vistas.add(columna)\n",
    "            else:\n",
    "                print(f\"   üóëÔ∏è  Eliminando columna duplicada: '{columna}'\")\n",
    "        return df[columnas_a_mantener]\n",
    "    \n",
    "    def _reordenar_columnas(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        orden_preferido = self.config_limpieza.get('columnas_orden_preferido', [])\n",
    "        columnas_ordenadas = [col for col in orden_preferido if col in df.columns]\n",
    "        columnas_restantes = [col for col in df.columns if col not in columnas_ordenadas]\n",
    "        columnas_finales = columnas_ordenadas + sorted(columnas_restantes)\n",
    "        if columnas_finales != df.columns.tolist():\n",
    "            print(\"üîÑ Reordenando columnas...\")\n",
    "            df = df[columnas_finales]\n",
    "        return df\n",
    "    # --- FIN M√âTODOS DE C√ÅLCULO Y ESTRUCTURA ---\n",
    "\n",
    "\n",
    "    # --- M√âTODOS DE ESTAD√çSTICAS Y MAIN ---\n",
    "    def _calcular_estadisticas_limpieza(self, registros_originales: int):\n",
    "        self.estadisticas_limpieza = {\n",
    "            'registros_originales': registros_originales,\n",
    "            'registros_finales': len(self.df),\n",
    "            'columnas_finales': len(self.df.columns),\n",
    "            'nulos_por_columna': self.df.isnull().sum().to_dict(),\n",
    "            'registros_eliminados': registros_originales - len(self.df),\n",
    "            'porcentaje_completitud': (1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100\n",
    "        }\n",
    "    \n",
    "    def _mostrar_resumen_limpieza(self):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä RESUMEN DE LIMPIEZA AUTOMATIZADA\")\n",
    "        print(\"=\"*60)\n",
    "        stats = self.estadisticas_limpieza\n",
    "        print(f\"üìà Registros originales: {stats['registros_originales']:,}\")\n",
    "        print(f\"üìà Registros finales: {stats['registros_finales']:,}\")\n",
    "        print(f\"üìä Columnas finales: {stats['columnas_finales']}\")\n",
    "        print(f\"üóëÔ∏è  Registros eliminados: {stats['registros_eliminados']:,}\")\n",
    "        print(f\"‚úÖ Completitud: {stats['porcentaje_completitud']:.1f}%\")\n",
    "        \n",
    "        print(\"\\nüìã COLUMNAS FINALES (ORDENADAS):\")\n",
    "        for i, columna in enumerate(self.df.columns, 1):\n",
    "            nulos = stats['nulos_por_columna'][columna]\n",
    "            total = len(self.df)\n",
    "            porcentaje_valido = ((total - nulos)/total)*100\n",
    "            print(f\"   {i:2d}. {columna}: {total - nulos}/{total} v√°lidos ({porcentaje_valido:.1f}%)\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "    def guardar_datos_limpios(self, archivo_salida: str = \"datos_limpios.csv\"):\n",
    "        \"\"\"Guardar datos limpios\"\"\"\n",
    "        try:\n",
    "            self.df = self._eliminar_columnas_duplicadas(self.df)\n",
    "            self.df.to_csv(archivo_salida, index=False, encoding='utf-8')\n",
    "            print(f\"\\nüíæ Datos guardados en: {archivo_salida}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error guardando archivo: {e}\")\n",
    "            return False\n",
    "\n",
    "    def generar_reporte_calidad(self, archivo_reporte: str = \"reporte_calidad.png\"):\n",
    "        \"\"\"Generar reporte de calidad de datos con visualizaciones (M√âTODO FALTANTE)\"\"\"\n",
    "        try:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            \n",
    "            # Gr√°fico de nulos por columna\n",
    "            nulos_por_columna = self.df.isnull().sum().sort_values(ascending=False)\n",
    "            sns.barplot(x=nulos_por_columna.values, y=nulos_por_columna.index, ax=axes[0], palette=\"viridis\")\n",
    "            axes[0].set_title('Valores Nulos por Columna')\n",
    "            axes[0].set_xlabel('Cantidad de Valores Nulos')\n",
    "            axes[0].set_ylabel('Columna')\n",
    "            \n",
    "            # Gr√°fico de tipos de datos\n",
    "            tipos_datos = self.df.dtypes.astype(str).value_counts()\n",
    "            axes[1].pie(tipos_datos.values, labels=tipos_datos.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"pastel\"))\n",
    "            axes[1].set_title('Distribuci√≥n de Tipos de Datos Finales')\n",
    "            axes[1].axis('equal')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(archivo_reporte, dpi=300)\n",
    "            plt.close(fig)\n",
    "            print(f\"üìä Reporte de calidad generado: {archivo_reporte}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† No se pudo generar reporte visual: {e}\")\n",
    "            return False\n",
    "\n",
    "    def detectar_estructura(self) -> Dict:\n",
    "        \"\"\"Detectar autom√°ticamente la estructura del archivo (M√âTODO FALTANTE)\"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.archivo_csv, nrows=1000)\n",
    "            self.df = self._reorganizar_datos_mal_estructurados(self.df)\n",
    "            mapeo_automatico = self._mapear_columnas_automatico(self.df.columns.tolist())\n",
    "            \n",
    "            df_temp = self.df.rename(columns=mapeo_automatico)\n",
    "            tipos_datos = {}\n",
    "            for col in df_temp.columns:\n",
    "                tipos_datos[col] = {'tipo_probable': self._determinar_tipo_columna(df_temp[col]), 'ejemplos': df_temp[col].dropna().unique().tolist()[:3]}\n",
    "\n",
    "            return {\n",
    "                'mapeo_propuesto': mapeo_automatico,\n",
    "                'tipos_datos': tipos_datos,\n",
    "                'muestra_datos': df_temp.head(3).to_dict('records')\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error detectando estructura: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def aplicar_limpieza(self, mapeo_personalizado: Dict = None) -> pd.DataFrame:\n",
    "        \"\"\"Aplicar limpieza completa a los datos (MAIN METHOD)\"\"\"\n",
    "        print(\"\\nüßπ APLICANDO LIMPIEZA AUTOMATIZADA...\")\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(self.archivo_csv)\n",
    "            registros_originales = len(self.df)\n",
    "            \n",
    "            # Flujo de Limpieza\n",
    "            self.df = self._reorganizar_datos_mal_estructurados(self.df)\n",
    "            mapeo_final = mapeo_personalizado or self._mapear_columnas_automatico(self.df.columns.tolist())\n",
    "            self.df = self.df.rename(columns=mapeo_final)\n",
    "            print(\"‚úÖ Columnas renombradas\")\n",
    "            self.df = self._eliminar_columnas_duplicadas(self.df)\n",
    "            self.df = self._detectar_y_corregir_pais(self.df)\n",
    "            self._aplicar_limpieza_por_tipo()\n",
    "            self._calcular_total_ventas()\n",
    "            self.df = self._reordenar_columnas(self.df)\n",
    "            \n",
    "            # Finalizaci√≥n\n",
    "            self._calcular_estadisticas_limpieza(registros_originales)\n",
    "            self._mostrar_resumen_limpieza()\n",
    "            \n",
    "            return self.df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en limpieza: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# --- FIN CLASE LimpiezaAutomatizada ---\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN DE USO R√ÅPIDO (FALTANTE) ---\n",
    "\n",
    "def limpiar_csv_automatico(archivo_csv: str, archivo_salida: str = \"datos_limpios.csv\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funci√≥n de uso r√°pido para limpieza autom√°tica\n",
    "    \"\"\"\n",
    "    limpiador = LimpiezaAutomatizada(archivo_csv)\n",
    "    \n",
    "    # 1. Detectar estructura\n",
    "    estructura = limpiador.detectar_estructura()\n",
    "    print(\"\\nüîç MAPEO AUTOM√ÅTICO PROPUESTO:\")\n",
    "    for orig, nuevo in estructura['mapeo_propuesto'].items():\n",
    "        print(f\"   '{orig}' ‚Üí '{nuevo}'\")\n",
    "    \n",
    "    # 2. Aplicar limpieza\n",
    "    df_limpio = limpiador.aplicar_limpieza()\n",
    "    \n",
    "    if not df_limpio.empty:\n",
    "        # 3. Persistir y reportar\n",
    "        limpiador.guardar_datos_limpios(archivo_salida)\n",
    "        limpiador.generar_reporte_calidad()\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Esta secci√≥n no se ejecuta en el notebook, pero es buena pr√°ctica mantenerla.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88182315",
   "metadata": {},
   "source": [
    "## Celda 2: Ejecuci√≥n del Flujo ETL (E/T)\n",
    "\n",
    "Esta celda ejecuta la limpieza y genera las tablas de dimensi√≥n y la tabla de hechos con sus claves for√°neas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb8393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Limpieza y Normalizaci√≥n de Hechos (Fact Table) ---\n",
      "üîÑ Reorganizando datos mal estructurados...\n",
      "   ‚úÖ Datos reorganizados: 1000 filas\n",
      "\n",
      "üîç MAPEO AUTOM√ÅTICO PROPUESTO:\n",
      "   'fecha' ‚Üí 'fecha'\n",
      "   'producto' ‚Üí 'producto'\n",
      "   'tipo_producto' ‚Üí 'tipo_producto'\n",
      "   'cantidad' ‚Üí 'cantidad'\n",
      "   'precio_unitario' ‚Üí 'precio_unitario'\n",
      "   'tipo_venta' ‚Üí 'tipo_venta'\n",
      "   'tipo_cliente' ‚Üí 'tipo_cliente'\n",
      "   'descuento' ‚Üí 'descuento'\n",
      "   'costo_envio' ‚Üí 'costo_envio'\n",
      "   'ciudad' ‚Üí 'ciudad'\n",
      "   'pais' ‚Üí 'pais'\n",
      "\n",
      "üßπ APLICANDO LIMPIEZA AUTOMATIZADA...\n",
      "üîÑ Reorganizando datos mal estructurados...\n",
      "   ‚úÖ Datos reorganizados: 1250000 filas\n",
      "‚úÖ Columnas renombradas\n",
      "üîç Buscando columnas duplicadas...\n",
      "   üó∫Ô∏è  Detectando pa√≠ses basado en ciudades...\n",
      "   ‚úÖ Pa√≠ses detectados: {'Desconocido': 923690, 'Colombia': 76580, 'Per√∫': 44859, 'Argentina': 44687, 'Espa√±a': 44561, 'Chile': 44494, 'M√©xico': 35624, 'Estados Unidos': 35505}\n",
      "üßπ Aplicando limpieza por tipo de dato...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_4628\\307013661.py:205: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  if columna in ['cantidad', 'precio_unitario']: self.df[columna].fillna(0, inplace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_4628\\307013661.py:205: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  if columna in ['cantidad', 'precio_unitario']: self.df[columna].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Limpieza por tipo de dato completada.\n",
      "üí∞ Calculando columna total_ventas...\n",
      "   ‚úÖ Total_ventas calculado.\n",
      "üîÑ Reordenando columnas...\n",
      "\n",
      "============================================================\n",
      "üìä RESUMEN DE LIMPIEZA AUTOMATIZADA\n",
      "============================================================\n",
      "üìà Registros originales: 1,250,000\n",
      "üìà Registros finales: 1,250,000\n",
      "üìä Columnas finales: 12\n",
      "üóëÔ∏è  Registros eliminados: 0\n",
      "‚úÖ Completitud: 100.0%\n",
      "\n",
      "üìã COLUMNAS FINALES (ORDENADAS):\n",
      "    1. fecha: 1248620/1250000 v√°lidos (99.9%)\n",
      "    2. producto: 1250000/1250000 v√°lidos (100.0%)\n",
      "    3. tipo_producto: 1250000/1250000 v√°lidos (100.0%)\n",
      "    4. cantidad: 1250000/1250000 v√°lidos (100.0%)\n",
      "    5. precio_unitario: 1250000/1250000 v√°lidos (100.0%)\n",
      "    6. ciudad: 1250000/1250000 v√°lidos (100.0%)\n",
      "    7. pais: 1250000/1250000 v√°lidos (100.0%)\n",
      "    8. tipo_venta: 1250000/1250000 v√°lidos (100.0%)\n",
      "    9. tipo_cliente: 1250000/1250000 v√°lidos (100.0%)\n",
      "   10. descuento: 1248049/1250000 v√°lidos (99.8%)\n",
      "   11. costo_envio: 1248091/1250000 v√°lidos (99.8%)\n",
      "   12. total_ventas: 1250000/1250000 v√°lidos (100.0%)\n",
      "============================================================\n",
      "üîç Buscando columnas duplicadas...\n",
      "\n",
      "üíæ Datos guardados en: ventas_temp_limpio.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_4628\\307013661.py:379: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=nulos_por_columna.values, y=nulos_por_columna.index, ax=axes[0], palette=\"viridis\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Reporte de calidad generado: reporte_calidad.png\n",
      "\n",
      "--- 2. Extracci√≥n y Generaci√≥n de Dimensiones ---\n",
      "‚úÖ Generada Dimensi√≥n TIPOS_CLIENTES\n",
      "‚úÖ Generada Dimensi√≥n PRODUCTOS\n",
      "\n",
      "--- 3. Mapeo de Claves For√°neas (FK) en la Tabla de Hechos ---\n",
      "\n",
      "--- Vista Previa del DataFrame de Hechos con FKs (Listo para Carga) ---\n",
      "   producto_fk  tipo_cliente_fk       fecha        ciudad     tipo_venta  \\\n",
      "0           84                1  2025-10-30      Santiago         Online   \n",
      "1           84                2  2025-11-17       C√≥rdoba   Distribuidor   \n",
      "2           89                2  2025-10-22  Barranquilla   Distribuidor   \n",
      "3           75                2  2025-10-20      New York  Tienda_F√≠sica   \n",
      "4           89                3  2025-10-20        Madrid   Distribuidor   \n",
      "\n",
      "             pais  cantidad  precio_unitario  descuento  costo_envio  \\\n",
      "0           Chile       2.0           3681.0       0.20          0.0   \n",
      "1     Desconocido       7.0           2321.0       0.15          0.0   \n",
      "2     Desconocido       9.0           3540.0       0.20          0.0   \n",
      "3  Estados Unidos       3.0           3287.0       0.05          0.0   \n",
      "4          Espa√±a       2.0           3414.0       0.00          0.0   \n",
      "\n",
      "   total_ventas  \n",
      "0     7347.2760  \n",
      "1    16222.6295  \n",
      "2    31796.2800  \n",
      "3     9856.0695  \n",
      "4     6828.0000  \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## H2.ipynb - Celda 2: Ejecuci√≥n de Limpieza y Generaci√≥n del Esquema Estrella\n",
    "\n",
    "# 1. Definir el archivo de entrada\n",
    "ARCHIVO_VENTAS = 'ventas.csv' # Aseg√∫rate de que este archivo exista\n",
    "\n",
    "# 2. Inicializar y ejecutar la limpieza usando la funci√≥n de uso r√°pido\n",
    "print(\"--- 1. Limpieza y Normalizaci√≥n de Hechos (Fact Table) ---\")\n",
    "df_hechos_limpio = limpiar_csv_automatico(ARCHIVO_VENTAS, archivo_salida='ventas_temp_limpio.csv')\n",
    "\n",
    "# --- 3. GENERACI√ìN DE TABLAS DE DIMENSI√ìN ---\n",
    "\n",
    "if not df_hechos_limpio.empty:\n",
    "    \n",
    "    print(\"\\n--- 2. Extracci√≥n y Generaci√≥n de Dimensiones ---\")\n",
    "    \n",
    "    # a) Dimensi√≥n: TIPOS_CLIENTES (Dim_Tipo_Cliente)\n",
    "    df_tipos_clientes = df_hechos_limpio[['tipo_cliente']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "    df_tipos_clientes['tipo_cliente_id'] = df_tipos_clientes.index + 1 \n",
    "    DF_DIM_TIPOS_CLIENTES = df_tipos_clientes[['tipo_cliente_id', 'tipo_cliente']].rename(\n",
    "        columns={'tipo_cliente': 'nombre_tipo_cliente'}\n",
    "    ).copy()\n",
    "    print(\"‚úÖ Generada Dimensi√≥n TIPOS_CLIENTES\")\n",
    "\n",
    "\n",
    "    # b) Dimensi√≥n: PRODUCTOS (Dim_Producto)\n",
    "    df_productos = df_hechos_limpio[['producto', 'tipo_producto']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "    df_productos['producto_id'] = df_productos.index + 1 \n",
    "    DF_DIM_PRODUCTOS = df_productos[['producto_id', 'producto', 'tipo_producto']].rename(\n",
    "        columns={'producto': 'nombre_producto', 'tipo_producto': 'nombre_tipo_producto'}\n",
    "    ).copy()\n",
    "    print(\"‚úÖ Generada Dimensi√≥n PRODUCTOS\")\n",
    "\n",
    "    \n",
    "    # --- 4. Mapeo de Claves For√°neas (FK) en la Tabla de Hechos ---\n",
    "    print(\"\\n--- 3. Mapeo de Claves For√°neas (FK) en la Tabla de Hechos ---\")\n",
    "    \n",
    "    # Mapeo de Tipo Cliente\n",
    "    map_tipo_cliente = DF_DIM_TIPOS_CLIENTES.set_index('nombre_tipo_cliente')['tipo_cliente_id'].to_dict()\n",
    "    df_hechos_limpio['tipo_cliente_fk'] = df_hechos_limpio['tipo_cliente'].map(map_tipo_cliente).fillna(0).astype(int) # Usar 0 para Desconocido/Nulo\n",
    "    \n",
    "    # Mapeo de Producto\n",
    "    map_producto = DF_DIM_PRODUCTOS.set_index('nombre_producto')['producto_id'].to_dict()\n",
    "    df_hechos_limpio['producto_fk'] = df_hechos_limpio['producto'].map(map_producto).fillna(0).astype(int) # Usar 0 para Desconocido/Nulo\n",
    "    \n",
    "    \n",
    "    # --- 5. TABLA DE HECHOS FINAL (Fact_Ventas) ---\n",
    "    columnas_fact_table = [\n",
    "        'producto_fk', 'tipo_cliente_fk', # <--- Claves For√°neas\n",
    "        'fecha', 'ciudad', 'tipo_venta', 'pais', # <--- Dimensiones Degradadas\n",
    "        'cantidad', 'precio_unitario', 'descuento', 'costo_envio', 'total_ventas' # <--- M√©tricas\n",
    "    ]\n",
    "    \n",
    "    DF_FACT_VENTAS = df_hechos_limpio[columnas_fact_table].copy()\n",
    "    \n",
    "    print(\"\\n--- Vista Previa del DataFrame de Hechos con FKs (Listo para Carga) ---\")\n",
    "    print(DF_FACT_VENTAS.head())\n",
    "    print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"‚ùå El DataFrame de hechos no pudo ser limpiado/cargado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54600801",
   "metadata": {},
   "source": [
    "## Celda 3: Persistencia de Datos Limpios\n",
    "\n",
    "Esta celda guarda las tablas generadas en el disco, listas para la Carga (L) final en el DWH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5b545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dimensi√≥n TIPOS_CLIENTES guardada en: carga_d_tipos_clientes.csv\n",
      "‚úÖ Dimensi√≥n PRODUCTOS guardada en: carga_d_productos.csv\n",
      "‚úÖ Hechos VENTAS guardados en: carga_f_ventas.csv\n",
      "\n",
      "üéâ Proceso ETL (E/T) completado. Los CSVs est√°n listos para la Carga (L) en el Star Schema.\n"
     ]
    }
   ],
   "source": [
    "## H2.ipynb - Celda 3: Persistencia de Datos Limpios (Listo para Cargar en BD)\n",
    "\n",
    "if 'DF_DIM_TIPOS_CLIENTES' in locals() and 'DF_FACT_VENTAS' in locals():\n",
    "    \n",
    "    # 1. Guardar la Dimensi√≥n TIPOS_CLIENTES\n",
    "    RUTA_DIM_TIPOS_CLIENTES = 'carga_d_tipos_clientes.csv'\n",
    "    DF_DIM_TIPOS_CLIENTES.to_csv(RUTA_DIM_TIPOS_CLIENTES, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Dimensi√≥n TIPOS_CLIENTES guardada en: {RUTA_DIM_TIPOS_CLIENTES}\")\n",
    "    \n",
    "    # 2. Guardar la Dimensi√≥n PRODUCTOS\n",
    "    RUTA_DIM_PRODUCTOS = 'carga_d_productos.csv'\n",
    "    DF_DIM_PRODUCTOS.to_csv(RUTA_DIM_PRODUCTOS, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Dimensi√≥n PRODUCTOS guardada en: {RUTA_DIM_PRODUCTOS}\")\n",
    "    \n",
    "    # 3. Guardar la Tabla de Hechos VENTAS\n",
    "    RUTA_FACT_VENTAS = 'carga_f_ventas.csv'\n",
    "    DF_FACT_VENTAS.to_csv(RUTA_FACT_VENTAS, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Hechos VENTAS guardados en: {RUTA_FACT_VENTAS}\")\n",
    "    \n",
    "    print(\"\\nüéâ Proceso ETL (E/T) completado. Los CSVs est√°n listos para la Carga (L) en el Star Schema.\")\n",
    "else:\n",
    "    print(\"‚ùå No se pudieron generar los DataFrames finales. Verifique la Celda 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
